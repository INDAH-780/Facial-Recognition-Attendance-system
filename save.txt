import os
import json
import torch
import psycopg2
import numpy as np
import pandas as pd
from PIL import Image
from facenet_pytorch import InceptionResnetV1
from torchvision import datasets
from scipy.spatial.distance import cosine

# Initialize GPU/CPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f'Running on device: {device}')

# Initialize model
resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)

# PostgreSQL Database Connection
conn = psycopg2.connect(dbname="attendance_db", user="postgres", password="postgress123", host="localhost")
cursor = conn.cursor()

# Load Student Details from CSV
student_data = pd.read_csv("studentsName.csv")
student_info = {row["student_id"]: {"name": row["name"], "department": row["department"], "level": row["level"]}
                for _, row in student_data.iterrows()}

# Define Dataset Paths
detected_faces_path = "detectedFaces/"

# Check if we need to do face detection or can skip to embeddings
skip_detection = os.path.exists(detected_faces_path) and any(
    os.listdir(detected_faces_path)
)

if not skip_detection:
    print("No detected faces found. Running full pipeline...")
    from facenet_pytorch import MTCNN
    from torch.utils.data import DataLoader
    
    # Initialize MTCNN only if needed
    mtcnn = MTCNN(
        image_size=160,
        margin=20,
        keep_all=True,
        device=device,
        min_face_size=40,
        thresholds=[0.6, 0.7, 0.7]
    )
    
    dataset_path = "dataset/"
    os.makedirs(detected_faces_path, exist_ok=True)
    workers = 0 if os.name == 'nt' else 4

    class NamedImageFolder(datasets.ImageFolder):
        def __getitem__(self, index):
            original_tuple = super().__getitem__(index)
            path = self.samples[index][0]
            return original_tuple + (path,)

    dataset = NamedImageFolder(dataset_path)
    dataset.idx_to_class = {i: c for c, i in dataset.class_to_idx.items()}
    loader = DataLoader(dataset, collate_fn=lambda x: x[0], num_workers=workers)

    aligned_faces = []
    student_ids = []
    file_counter = {}

    for img, label, img_path in loader:
        faces, probs = mtcnn(img, return_prob=True)
        if faces is not None:
            student_id = dataset.idx_to_class[label]
            
            if student_id not in file_counter:
                file_counter[student_id] = 0
            
            for i, (face, prob) in enumerate(zip(faces, probs)):
                if prob < 0.7:
                    print(f'Skipping low-probability detection ({prob:.4f}) in {os.path.basename(img_path)}')
                    continue
                    
                print(f'Face detected for {student_id} in {os.path.basename(img_path)} with probability: {prob:.6f}')
                aligned_faces.append(face)
                student_ids.append(student_id)

                student_faces_folder = os.path.join(detected_faces_path, student_id)
                os.makedirs(student_faces_folder, exist_ok=True)

                original_name = os.path.splitext(os.path.basename(img_path))[0]
                save_name = f"{original_name}_{file_counter[student_id]}.jpg"
                file_counter[student_id] += 1

                img_array = face.permute(1, 2, 0).detach().cpu().numpy()
                img_array = (img_array * 255).astype(np.uint8)
                Image.fromarray(img_array).save(os.path.join(student_faces_folder, save_name))

    print("✅ Face detection completed. Cropped faces saved in 'detectedFaces/'!")
else:
    print("✅ Detected faces already exist. Loading from disk...")
    aligned_faces = []
    student_ids = []
    
    # Load all detected faces from disk
    for student_id in os.listdir(detected_faces_path):
        student_folder = os.path.join(detected_faces_path, student_id)
        if os.path.isdir(student_folder):
            for face_file in os.listdir(student_folder):
                if face_file.endswith('.jpg'):
                    face_path = os.path.join(student_folder, face_file)
                    img = Image.open(face_path)
                    img_array = np.array(img).astype(np.float32) / 255.0
                    face_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
                    aligned_faces.append(face_tensor)
                    student_ids.append(student_id)
    
    print(f"✅ Loaded {len(aligned_faces)} faces from disk")

# Step 2: Extract Embeddings & Store in PostgreSQL
if aligned_faces:
    aligned_faces = torch.cat(aligned_faces).to(device)
    embeddings = resnet(aligned_faces).detach().cpu()

    for i, student_id in enumerate(student_ids):
        student_details = student_info.get(student_id, {"name": "Unknown", "department": "Unknown", "level": "Unknown"})
        embedding_json = json.dumps(embeddings[i].tolist())

        cursor.execute("""
            INSERT INTO students (student_id, name, department, level, embedding)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (student_id) DO UPDATE SET embedding = EXCLUDED.embedding
        """, (student_id, student_details["name"], student_details["department"], student_details["level"], embedding_json))

    conn.commit()
    print("✅ Face embeddings stored successfully!")

# Step 3: Recognition
def recognize_face(new_embedding, stored_embedding):
    return 1 - cosine(new_embedding, stored_embedding)

cursor.execute("SELECT student_id, embedding FROM students")
stored_data = cursor.fetchall()

if aligned_faces:
    new_face_embedding = embeddings[0].tolist()
    recognized_student = None

    for student_id, stored_embedding_json in stored_data:
        stored_embedding = json.loads(stored_embedding_json)
        score = recognize_face(new_face_embedding, stored_embedding)

        if score > 0.8:
            recognized_student = student_id
            break

    if recognized_student:
        print(f"✅ Student Recognized: {recognized_student}")
    else:
        print("❌ Face not recognized.")

conn.close()